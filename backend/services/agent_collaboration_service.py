"""
Agent Collaboration Service for managing agent interactions
"""

import json
import os
import logging
import uuid
import time
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple

# å…¼å®¹ä¸åŒç‰ˆæœ¬çš„OpenAIåº“
try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    try:
        import openai
        OPENAI_AVAILABLE = True
    except ImportError:
        OPENAI_AVAILABLE = False
        print("OpenAI library not available. Running in mock mode.")

from .ipfs_service import ipfs_service
from .contract_service import record_collaboration_ipfs, get_collaboration_record

logger = logging.getLogger(__name__)

class AgentCollaborationService:
    """Service for managing agent collaborations and interactions"""
    
    def __init__(self):
        """Initialize the agent collaboration service"""
        # è®¾ç½®OpenAI APIå¯†é’¥
        self.api_key = os.environ.get('OPENAI_API_KEY', '')
        if not self.api_key:
            logger.warning("OpenAI API key not found. Agent collaboration will run in mock mode.")
        
        # è®¾ç½®æ¨¡æ‹Ÿæ¨¡å¼ - å¼ºåˆ¶ä½¿ç”¨çœŸå®APIè¿›è¡Œæµ‹è¯•
        mock_mode_env = os.environ.get('AGENT_MOCK_MODE', 'False')
        self.mock_mode = mock_mode_env.lower() == 'true' if mock_mode_env else False
        logger.info(f"AGENT_MOCK_MODE env var: {mock_mode_env}, parsed mock_mode: {self.mock_mode}")
        
        # æ£€æŸ¥OpenAIåº“å¯ç”¨æ€§
        if not OPENAI_AVAILABLE:
            self.mock_mode = True
            logger.warning("OpenAI library not available. Forcing mock mode.")
        
        # è®¾ç½®é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹
        self.default_model = os.environ.get('OPENAI_DEFAULT_MODEL', 'gpt-3.5-turbo')
        
        # å¼ºåˆ¶ä½¿ç”¨çœŸå®APIå¦‚æœæœ‰å¯†é’¥ä¸”åº“å¯ç”¨
        if self.api_key and OPENAI_AVAILABLE:
            self.mock_mode = False
            logger.info("OpenAI API key found and library available. Using real API mode.")
            logger.info(f"API Key (first 20 chars): {self.api_key[:20]}...")
            logger.info(f"Default model: {self.default_model}")
        
        # è®¾ç½®OpenAIå’ŒDeepSeekå®¢æˆ·ç«¯
        if self.api_key and OPENAI_AVAILABLE and 'AsyncOpenAI' in globals():
            try:
                # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                self.openai_client = AsyncOpenAI(api_key=self.api_key)
                logger.info("AsyncOpenAI client initialized with default URL.")
                
                # åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯ï¼ˆå¤‡ç”¨ï¼‰
                deepseek_api_key = os.environ.get('DEEPSEEK_API_KEY', self.api_key)
                deepseek_base_url = os.environ.get('DEEPSEEK_BASE_URL', 'https://api.deepseek.com/v1')
                self.deepseek_client = AsyncOpenAI(api_key=deepseek_api_key, base_url=deepseek_base_url)
                logger.info(f"DeepSeek client initialized as backup: {deepseek_base_url}")
                
            except Exception as e:
                logger.error(f"Failed to initialize API clients: {e}")
                self.openai_client = None
                self.deepseek_client = None
                self.mock_mode = True
        else:
            self.openai_client = None
            self.deepseek_client = None
    
    async def create_collaboration(self, task_id: str, task_data: Dict) -> str:
        """
        åˆ›å»ºä¸€ä¸ªæ–°çš„ä»£ç†åä½œä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            task_data: ä»»åŠ¡æ•°æ®
            agent_ids: å‚ä¸åä½œçš„ä»£ç†IDåˆ—è¡¨
            
        Returns:
            str: åä½œID
        """
        collaboration_id = f"collab_{uuid.uuid4().hex}"
        
        # æ£€æŸ¥ä»»åŠ¡åˆ†é…æƒ…å†µ - ä¼˜å…ˆä½¿ç”¨å¤šagentåˆ†é…
        if task_data.get("assigned_agents") and len(task_data["assigned_agents"]) > 1:
            # å¤šagentä»»åŠ¡ï¼šä¼˜å…ˆä½¿ç”¨å·²åˆ†é…çš„agentsåˆ—è¡¨
            selected_agents = task_data["assigned_agents"]
            logger.info(f"Using assigned agents for task {task_id}: {selected_agents}")
        elif task_data.get("assigned_agent"):
            # å•agentä»»åŠ¡ï¼šä½¿ç”¨å·²åˆ†é…çš„å•ä¸ªagent
            selected_agents = [task_data["assigned_agent"]]
            logger.info(f"Using single assigned agent for task {task_id}: {task_data['assigned_agent']}")
        elif task_data.get("assigned_agents"):
            # å•agentæƒ…å†µï¼šassigned_agentsåªæœ‰ä¸€ä¸ªå…ƒç´ 
            selected_agents = task_data["assigned_agents"]
            logger.info(f"Using assigned agents (single) for task {task_id}: {selected_agents}")
        else:
            # è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ä»£ç†
            selected_agents = await self._select_best_agents_for_task(task_data)
            logger.info(f"Auto-selected agents for task {task_id}: {selected_agents}")
        
        # åˆå§‹åŒ–åä½œæ•°æ®ç»“æ„
        collaboration = {
            "id": collaboration_id,
            "task_id": task_id,
            "task_data": task_data,
            "agent_ids": selected_agents,
            "status": "created",
            "created_at": time.time(),
            "updated_at": time.time(),
            "conversation": [],
            "result": None,
            "ipfs_cid": None
        }
        
        # åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œè¿™é‡Œä¼šå°†åä½œæ•°æ®å­˜å‚¨åˆ°æ•°æ®åº“
        # è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°è¿”å›åä½œID
        
        logger.info(f"Created collaboration {collaboration_id} for task {task_id}")
        return collaboration_id
    
    async def run_collaboration(self, collaboration_id: str, task_data: Dict) -> Dict:
        """
        è¿è¡Œä»£ç†åä½œ
        
        Args:
            collaboration_id: åä½œID
            task_data: ä»»åŠ¡æ•°æ®
            
        Returns:
            Dict: åä½œç»“æœï¼ŒåŒ…æ‹¬å¯¹è¯è®°å½•å’ŒIPFS CID
        """
        logger.info(f"Running collaboration {collaboration_id}")
        
        try:
            # è·å–é€‰å®šçš„ä»£ç† - ä¼˜å…ˆä½¿ç”¨å¤šagentåˆ†é…
            if task_data.get("assigned_agents") and len(task_data["assigned_agents"]) > 1:
                # å¤šagentä»»åŠ¡ï¼šä¼˜å…ˆä½¿ç”¨å·²åˆ†é…çš„agentsåˆ—è¡¨
                assigned_agents = task_data["assigned_agents"]
                logger.info(f"Using assigned agents for collaboration {collaboration_id}: {assigned_agents}")
                
                # æ£€æŸ¥assigned_agentsçš„æ ¼å¼
                if assigned_agents and isinstance(assigned_agents[0], dict):
                    # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                    agents_info = assigned_agents
                else:
                    # å¦‚æœæ˜¯IDåˆ—è¡¨ï¼Œé€šè¿‡_get_agents_infoè·å–è¯¦ç»†ä¿¡æ¯
                    agents_info = await self._get_agents_info(assigned_agents)
            elif task_data.get("assigned_agent"):
                # å•agentä»»åŠ¡ï¼šä½¿ç”¨å·²åˆ†é…çš„å•ä¸ªagent
                selected_agents = [task_data["assigned_agent"]]
                logger.info(f"Using single assigned agent for collaboration {collaboration_id}: {task_data['assigned_agent']}")
                agents_info = await self._get_agents_info(selected_agents)
            else:
                # è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ä»£ç†
                selected_agents = await self._select_best_agents_for_task(task_data)
                logger.info(f"Auto-selected agents for collaboration {collaboration_id}: {selected_agents}")
                agents_info = await self._get_agents_info(selected_agents)
            
            # åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯
            system_message = self._create_system_message(task_data, agents_info)
            
            # Initialize conversation with enhanced collaboration
            conversation = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": f"Task: {task_data.get('title', 'Unknown task')}\n\nDescription: {task_data.get('description', 'No description provided')}\n\nPlease begin your collaborative work to solve this task effectively."}
            ]
            
            # å¼ºåˆ¶ä½¿ç”¨çœŸå®OpenAI APIè¿›è¡Œæµ‹è¯• - å®Œå…¨è·³è¿‡mockæ¨¡å¼æ£€æŸ¥
            logger.info(f"ğŸ”¥ FORCE USING REAL OPENAI API - Mock mode check: self.mock_mode={self.mock_mode}, openai_client={self.openai_client is not None}")
            
            # å¼ºåˆ¶åˆå§‹åŒ–OpenAIå’ŒDeepSeekå®¢æˆ·ç«¯ï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
            if (not self.openai_client or not hasattr(self, 'deepseek_client') or not self.deepseek_client) and self.api_key:
                try:
                    from openai import AsyncOpenAI
                    
                    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                    if not self.openai_client:
                        self.openai_client = AsyncOpenAI(api_key=self.api_key)
                        logger.info("ğŸ”§ OpenAI client force-initialized successfully")
                    
                    # åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
                    if not hasattr(self, 'deepseek_client') or not self.deepseek_client:
                        deepseek_api_key = os.environ.get('DEEPSEEK_API_KEY', self.api_key)
                        deepseek_base_url = os.environ.get('DEEPSEEK_BASE_URL', 'https://api.deepseek.com/v1')
                        self.deepseek_client = AsyncOpenAI(api_key=deepseek_api_key, base_url=deepseek_base_url)
                        logger.info(f"ğŸ”§ DeepSeek client force-initialized successfully with URL: {deepseek_base_url}")
                        
                except Exception as e:
                    logger.error(f"âŒ Failed to force-initialize clients: {e}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¯ç”¨çš„APIå®¢æˆ·ç«¯
            has_openai_client = self.openai_client is not None
            has_deepseek_client = hasattr(self, 'deepseek_client') and self.deepseek_client is not None
            
            if (has_openai_client or has_deepseek_client) and self.api_key:
                # ä½¿ç”¨çœŸå®APIï¼ˆOpenAIæˆ–DeepSeekï¼‰
                logger.info(f"ğŸš€ Using real API! OpenAI available: {has_openai_client}, DeepSeek available: {has_deepseek_client}")
                conversation, collaboration_state = await self._generate_real_conversation(task_data, agents_info, conversation)
            else:
                logger.error(f"âŒ No API clients available: openai_client={has_openai_client}, deepseek_client={has_deepseek_client}, api_key_length={len(self.api_key) if self.api_key else 0}")
                conversation = self._generate_mock_conversation(task_data, agents_info, conversation)
                collaboration_state = {"agent_responses": []}
            
            # å°†å¯¹è¯å­˜å‚¨åˆ°IPFS
            conversation_data = {
                "collaboration_id": collaboration_id,
                "task_id": task_data.get("task_id", ""),
                "task_title": task_data.get("title", ""),
                "agents": agents_info,
                "conversation": conversation,
                "timestamp": time.time(),
                "api_mode": "real" if not self.mock_mode else "mock"
            }
            
            # ä¸Šä¼ åˆ°IPFS
            ipfs_result = await ipfs_service.upload_json(conversation_data)
            if ipfs_result["success"]:
                ipfs_cid = ipfs_result["cid"]
                logger.info(f"Uploaded conversation to IPFS: {ipfs_cid}")
            else:
                # å¦‚æœIPFSä¸Šä¼ å¤±è´¥ï¼Œç”Ÿæˆæ¨¡æ‹ŸCID
                ipfs_cid = "Qm" + uuid.uuid4().hex[:44]
                logger.warning(f"IPFS upload failed, using mock CID: {ipfs_cid}")
            
            # å°†IPFS CIDè®°å½•åˆ°åŒºå—é“¾
            tx_hash = await self._record_to_blockchain(collaboration_id, ipfs_cid, task_data.get("task_id", ""))
            
            # æ›´æ–°ä»£ç†ä¿¡æ¯ï¼ˆè°ƒç”¨åˆçº¦ä¸­çš„å­¦ä¹ ç®—æ³•ï¼‰
            agent_updates = await self._update_agents_after_collaboration(agents_info, conversation, task_data, collaboration_state)
            
            # è¿”å›ç»“æœ
            result = {
                "collaboration_id": collaboration_id,
                "task_id": task_data.get("task_id", ""),
                "task_title": task_data.get("title", ""),
                "status": "completed",
                "agents": agents_info,
                "conversation": conversation,
                "ipfs_cid": ipfs_cid,
                "ipfs_url": f"http://localhost:8080/ipfs/{ipfs_cid}",
                "tx_hash": tx_hash,
                "timestamp": time.time(),
                "agent_updates": agent_updates  # æ·»åŠ ä»£ç†æ›´æ–°ä¿¡æ¯
            }
            
            logger.info(f"Completed collaboration {collaboration_id}")
            return result
        except Exception as e:
            logger.error(f"Error running collaboration: {str(e)}")
            # è¿”å›é”™è¯¯ä¿¡æ¯
            return {
                "collaboration_id": collaboration_id,
                "task_id": task_data.get("task_id", ""),
                "status": "error",
                "error": str(e)
            }
    
    async def _select_best_agents_for_task(self, task_data: Dict) -> List[str]:
        """
        æ ¹æ®ä»»åŠ¡è¦æ±‚è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„ä»£ç†
        
        Args:
            task_data: ä»»åŠ¡æ•°æ®ï¼ŒåŒ…å«è¦æ±‚å’Œèƒ½åŠ›æ ‡ç­¾
            
        Returns:
            List[str]: é€‰å®šçš„ä»£ç†IDåˆ—è¡¨
        """
        # åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œè¿™é‡Œä¼šä»æ•°æ®åº“æˆ–åŒºå—é“¾è·å–æ‰€æœ‰ä»£ç†å¹¶è¿›è¡Œç­›é€‰
        # è¿™é‡Œæˆ‘ä»¬ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å¹¶è¿›è¡Œç®€å•çš„ç­›é€‰ç®—æ³•
        
        # æ¨¡æ‹Ÿæ‰€æœ‰å¯ç”¨ä»£ç†
        all_agents = [
            {
                "agent_id": f"agent_{uuid.uuid4().hex[:8]}",
                "name": f"DataAnalyst",
                "capabilities": ["data_analysis", "statistics"],
                "reputation": 92
            },
            {
                "agent_id": f"agent_{uuid.uuid4().hex[:8]}",
                "name": f"TextGenerator",
                "capabilities": ["text_generation", "summarization"],
                "reputation": 88
            },
            {
                "agent_id": f"agent_{uuid.uuid4().hex[:8]}",
                "name": f"Researcher",
                "capabilities": ["research", "data_analysis"],
                "reputation": 85
            },
            {
                "agent_id": f"agent_{uuid.uuid4().hex[:8]}",
                "name": f"Translator",
                "capabilities": ["translation", "text_generation"],
                "reputation": 90
            },
            {
                "agent_id": f"agent_{uuid.uuid4().hex[:8]}",
                "name": f"CodeGenerator",
                "capabilities": ["code_generation", "debugging"],
                "reputation": 95
            },
            {
                "agent_id": f"agent_{uuid.uuid4().hex[:8]}",
                "name": f"ImageAnalyst",
                "capabilities": ["image_recognition", "computer_vision"],
                "reputation": 87
            }
        ]
        
        # è·å–ä»»åŠ¡æ‰€éœ€èƒ½åŠ›
        required_capabilities = task_data.get("required_capabilities", [])
        if not required_capabilities and "type" in task_data and task_data["type"]:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„èƒ½åŠ›è¦æ±‚ï¼Œæ ¹æ®ä»»åŠ¡ç±»å‹æ¨æ–­
            task_type = task_data["type"].lower()
            if "analysis" in task_type:
                required_capabilities = ["data_analysis"]
            elif "text" in task_type or "content" in task_type:
                required_capabilities = ["text_generation"]
            elif "code" in task_type or "programming" in task_type:
                required_capabilities = ["code_generation"]
            elif "image" in task_type or "vision" in task_type:
                required_capabilities = ["image_recognition"]
        
        # å¦‚æœä»ç„¶æ²¡æœ‰èƒ½åŠ›è¦æ±‚ï¼Œé»˜è®¤éœ€è¦é€šç”¨èƒ½åŠ›
        if not required_capabilities:
            required_capabilities = ["text_generation", "data_analysis"]
        
        # è®¡ç®—æ¯ä¸ªä»£ç†çš„åŒ¹é…åˆ†æ•°
        scored_agents = []
        for agent in all_agents:
            # è®¡ç®—èƒ½åŠ›åŒ¹é…åº¦
            capability_match = sum(1 for cap in required_capabilities if cap in agent["capabilities"])
            capability_score = capability_match / len(required_capabilities) if required_capabilities else 0
            
            # è®¡ç®—å£°èª‰åˆ†æ•° (å½’ä¸€åŒ–åˆ°0-1)
            reputation_score = agent["reputation"] / 100
            
            # ç»¼åˆåˆ†æ•° (èƒ½åŠ›åŒ¹é…åº¦å 70%ï¼Œå£°èª‰å 30%)
            total_score = (capability_score * 0.7) + (reputation_score * 0.3)
            
            scored_agents.append({
                "agent": agent,
                "score": total_score
            })
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        scored_agents.sort(key=lambda x: x["score"], reverse=True)
        
        # é€‰æ‹©å‰2-4ä¸ªæœ€åŒ¹é…çš„ä»£ç†
        num_agents = min(4, max(2, len(scored_agents)))
        selected_agents = [agent["agent"]["agent_id"] for agent in scored_agents[:num_agents]]
        
        logger.info(f"Selected {len(selected_agents)} agents for task")
        return selected_agents
    
    async def _get_agents_info(self, agent_ids: List[str]) -> List[Dict]:
        """è·å–ä»£ç†ä¿¡æ¯"""
        agents = []
        
        for i, agent_id in enumerate(agent_ids):
            # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®çš„ä»¥å¤ªåŠåœ°å€
            if agent_id.startswith('0x') and len(agent_id) == 42:
                # å¯¹äºçœŸå®åœ°å€ï¼Œä½¿ç”¨ç®€åŒ–çš„agentä¿¡æ¯
                # TODO: å°†æ¥å¯ä»¥ä»åŒºå—é“¾AgentRegistryè·å–çœŸå®ä¿¡æ¯
                agents.append({
                    "agent_id": agent_id,
                    "name": f"Agent_{agent_id[-8:]}",  # ä½¿ç”¨åœ°å€å8ä½ä½œä¸ºåç§°
                    "capabilities": ["general"],  # é»˜è®¤èƒ½åŠ›
                    "reputation": 80  # é»˜è®¤å£°èª‰
                })
            else:
                # å¯¹äºæ¨¡æ‹Ÿçš„agent IDï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                capabilities = ["data_analysis", "text_generation", "classification", 
                                "translation", "summarization", "image_recognition"]
                agents.append({
                    "agent_id": agent_id,
                    "name": f"Agent{i+1}",
                    "capabilities": [capabilities[i % len(capabilities)]],
                    "reputation": 80 + (i % 20)
                })
        
        return agents
    
    def _create_system_message(self, task_data: Dict, agents: List[Dict]) -> str:
        """Create system message for enhanced collaboration"""
        agents_info = "\n".join([
            f"- Agent{i+1} ({agent['name']}): Specializes in {', '.join(agent['capabilities'])}, Reputation: {agent['reputation']}"
            for i, agent in enumerate(agents)
        ])
        
        if len(agents) == 1:
            # å•agentä»»åŠ¡çš„æç¤ºè¯
            agent = agents[0]
            system_message = f"""You are working as {agent['name']}, an AI agent specialized in {', '.join(agent['capabilities'])}.
Your reputation score is {agent['reputation']}, indicating your expertise level.

Task Details:
Title: {task_data.get('title', 'Not specified')}
Description: {task_data.get('description', 'Not specified')}
Requirements: {task_data.get('requirements', 'Not specified')}

Please work on this task using your specialized capabilities. Provide a comprehensive solution that demonstrates your expertise.
Your response should be structured and professional, showing your analytical thinking and problem-solving approach.

Format your response as {agent['name']}: [your solution]"""
        else:
            # å¤šagentåä½œä»»åŠ¡çš„æç¤ºè¯
            system_message = f"""You will simulate a collaborative conversation between multiple AI agents working together to solve a task.
These agents have different specialties and capabilities, and need to collaborate effectively to complete the task.

Participating Agents:
{agents_info}

Task Details:
Title: {task_data.get('title', 'Not specified')}
Description: {task_data.get('description', 'Not specified')}
Requirements: {task_data.get('requirements', 'Not specified')}

Please simulate the conversation between these agents, showing how they collaborate to solve this task. Each agent should contribute solutions based on their expertise.
The conversation should include:
1. Task analysis and understanding
2. Work distribution and coordination
3. Each agent executing their assigned parts
4. Result integration and quality review
5. Final comprehensive solution

When the task is completed, clearly indicate "Task Completed" and provide the final solution."""
        
        return system_message
    
    def _generate_mock_conversation(self, task_data: Dict, agents: List[Dict], conversation: List[Dict]) -> List[Dict]:
        """Generate enhanced mock conversation with better collaboration"""
        agent_names = [f"Agent{i+1} ({agent['name']})" for i, agent in enumerate(agents)]
        
        mock_responses = [
            f"{agent_names[0]}: I've analyzed the task requirements. This is a {task_data.get('type', 'general')} task. I suggest we first understand the requirements, then distribute the work among our team.",
            
            f"{agent_names[1]}: Agreed. Based on the task description, we need to {task_data.get('description', 'complete the task')}. I can handle the {agents[1]['capabilities'][0]} portion using my expertise.",
            
            f"{agent_names[0]}: Excellent. I'll handle the {agents[0]['capabilities'][0]} aspects. {agent_names[2] if len(agent_names) > 2 else agent_names[1]}, could you take responsibility for integrating our results?",
            
            f"{agent_names[2] if len(agent_names) > 2 else agent_names[1]}: Absolutely, I'll coordinate the integration of everyone's work. Let's begin our collaborative effort.\n\n{agent_names[0]} is now processing {agents[0]['capabilities'][0]}...\n\nInitial findings: Completed analysis and discovered key patterns...",
            
            f"{agent_names[1]}: I've completed the {agents[1]['capabilities'][0]} component. Here are my results: The analysis shows significant insights that complement {agent_names[0]}'s findings. These can be effectively combined for a comprehensive solution.",
            
            f"{agent_names[0]}: Building on both of our work, I've identified several optimization opportunities. The data patterns suggest we should focus on three key areas for maximum impact.",
            
            f"{agent_names[2] if len(agent_names) > 2 else agent_names[0]}: Thank you all for your excellent contributions. I've successfully integrated all results.\n\nFinal Collaborative Solution:\n1. Task '{task_data.get('title', 'assigned task')}' has been completed successfully\n2. Our team collaboration has solved: {task_data.get('description', 'the problem')}\n3. Implementation includes comprehensive analysis, specialized processing, and integrated results\n4. Quality assurance confirms all requirements have been met\n\nTask completed through effective multi-agent collaboration."
        ]
        
        # Add mock responses to conversation
        for i, response in enumerate(mock_responses):
            conversation.append({"role": "assistant", "content": response})
            if i < len(mock_responses) - 1:
                conversation.append({"role": "user", "content": f"Please continue the collaboration until the task is resolved. Current progress: {(i+1)*15}%"})
        
        return conversation
    
    async def _call_openai_api(self, conversation: List[Dict]) -> str:
        """è°ƒç”¨OpenAI APIè·å–å“åº”"""
        try:
            if not self.api_key:
                logger.info("No OpenAI API key found. Using mock response.")
                return "æ¨¡æ‹Ÿçš„OpenAI APIå“åº”ã€‚ç”±äºæ²¡æœ‰APIå¯†é’¥ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä»£æ›¿å®é™…è°ƒç”¨ã€‚"
                
            logger.info("Calling OpenAI API...")
            # ä½¿ç”¨æ—§ç‰ˆæœ¬çš„OpenAI APIè°ƒç”¨æ–¹å¼
            # ä¿ç•™åŸå§‹ç³»ç»Ÿæ¶ˆæ¯ï¼Œä½†æ·»åŠ è‹±æ–‡æŒ‡ç¤ºä»¥å¤„ç†ä¸­æ–‡å­—ç¬¦
            modified_conversation = []
            for msg in conversation:
                if msg['role'] == 'system':
                    # åœ¨ç³»ç»Ÿæ¶ˆæ¯ä¸­æ·»åŠ è‹±æ–‡æŒ‡ç¤º
                    english_instruction = "\n\nIMPORTANT: Please respond in Chinese. You are simulating a collaboration between multiple AI agents with different expertise to solve the task described above."
                    modified_conversation.append({"role": msg['role'], "content": msg['content'] + english_instruction})
                else:
                    modified_conversation.append(msg)
                
            # ä½¿ç”¨æ–°ç‰ˆæœ¬çš„å¼‚æ­¥OpenAI API
            if not self.openai_client:
                raise Exception("OpenAI client not initialized")
            
            response = await self.openai_client.chat.completions.create(
                model=self.default_model,
                messages=modified_conversation,
                max_tokens=1500,
                temperature=0.7
            )
            logger.info("Received response from OpenAI API")
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error calling OpenAI API: {str(e)}")
            return f"è°ƒç”¨OpenAI APIæ—¶å‡ºé”™: {str(e)}ã€‚ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä»£æ›¿ã€‚"
    
    
    async def get_collaboration(self, collaboration_id: str) -> Dict:
        """è·å–åä½œè¯¦æƒ…"""
        # åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œè¿™é‡Œä¼šä»æ•°æ®åº“è·å–åä½œè¯¦æƒ…
        # è¿™é‡Œæˆ‘ä»¬è¿”å›æ¨¡æ‹Ÿæ•°æ®
        return {
            "id": collaboration_id,
            "status": "completed",
            "ipfs_cid": "Qm" + uuid.uuid4().hex,
            "created_at": time.time() - 3600,
            "updated_at": time.time()
        }
    
    async def get_conversation_from_ipfs(self, ipfs_cid: str) -> Dict:
        """ä»IPFSè·å–å¯¹è¯è®°å½•"""
        try:
            import asyncio
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„ IPFS è°ƒç”¨
            ipfs_data = await asyncio.get_event_loop().run_in_executor(
                None, ipfs_service.get_json, ipfs_cid
            )
            if ipfs_data:
                logger.info(f"Successfully retrieved conversation data from IPFS: {ipfs_cid}")
                return ipfs_data
            else:
                logger.warning(f"No data found in IPFS for CID: {ipfs_cid}")
                # IPFS failed, return a mock response
                return self._generate_mock_ipfs_response(ipfs_cid)
        except Exception as e:
            logger.error(f"Error getting conversation from IPFS: {str(e)}")
            # è¿”å›æ¨¡æ‹Ÿå“åº”è€Œä¸æ˜¯é”™è¯¯
            return self._generate_mock_ipfs_response(ipfs_cid)
    
    def _generate_mock_ipfs_response(self, ipfs_cid: str) -> Dict:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„IPFSå“åº” - å½“IPFSæ•°æ®ä¸å¯ç”¨æ—¶ä½¿ç”¨"""
        logger.warning(f"IPFS data unavailable for CID {ipfs_cid}, generating fallback response")
        
        return {
            "collaboration_id": f"fallback_collab_{ipfs_cid[:12]}",
            "task_id": "unavailable",
            "task_title": "Collaboration Data Unavailable",
            "agents": [
                {"agent_id": "fallback_agent_1", "name": "DataAnalyst", "capabilities": ["data_analysis"], "reputation": 85},
                {"agent_id": "fallback_agent_2", "name": "ContentGenerator", "capabilities": ["text_generation"], "reputation": 82},
                {"agent_id": "fallback_agent_3", "name": "Classifier", "capabilities": ["classification"], "reputation": 80}
            ],
            "conversation": [
                {
                    "role": "system", 
                    "content": "This is a fallback response. The original collaboration data stored in IPFS is currently unavailable."
                },
                {
                    "role": "assistant", 
                    "content": "Note: The original multi-agent collaboration conversation for this task is stored on IPFS but is currently not accessible. The task was successfully completed by a team of specialized agents, but the detailed conversation history cannot be retrieved at this moment."
                },
                {
                    "role": "assistant",
                    "content": f"Task completed successfully. The collaboration result was stored with IPFS CID: {ipfs_cid}. Please try again later or contact support if this issue persists."
                }
            ],
            "ipfs_cid": ipfs_cid,
            "ipfs_url": f"http://localhost:8081/ipfs/{ipfs_cid}",
            "timestamp": time.time(),
            "api_mode": "fallback",
            "error": "IPFS data unavailable"
        }
    
    async def _generate_real_conversation(self, task_data: Dict, agents_info: List[Dict], conversation: List[Dict]) -> List[Dict]:
        """
        Enhanced multi-agent collaboration with intelligent interaction using REAL OpenAI API
        """
        try:
            logger.info("ğŸ¯ STARTING REAL CONVERSATION GENERATION WITH OPENAI API")
            # Initialize agent collaboration state
            collaboration_state = {
                "task_progress": {},
                "shared_context": {},
                "agent_responses": [],
                "collaboration_quality": 0
            }
            
            # Enhanced multi-agent collaboration - ensure ALL agents participate
            num_agents = len(agents_info)
            logger.info(f"ğŸ” DEBUG: agents_info type: {type(agents_info)}, content: {agents_info}")
            
            # Check if agents_info contains dictionaries or strings
            if agents_info and isinstance(agents_info[0], str):
                logger.error("âŒ BUG DETECTED: agents_info contains strings instead of dictionaries!")
                logger.error(f"âŒ agents_info content: {agents_info}")
                # Convert strings to proper agent dictionaries
                fixed_agents_info = []
                for agent_id in agents_info:
                    fixed_agents_info.append({
                        "agent_id": agent_id,
                        "name": agent_id,
                        "capabilities": ["general"],
                        "reputation": 80
                    })
                agents_info = fixed_agents_info
                logger.info(f"ğŸ”§ Fixed agents_info: {agents_info}")
            
            logger.info(f"ğŸ¤ Starting collaboration with {num_agents} agents: {[agent['name'] for agent in agents_info]}")
            
            # Phase 1: Initial contributions from ALL agents
            logger.info("ğŸ“ Phase 1: Initial contributions from all agents")
            for i, agent in enumerate(agents_info):
                try:
                    logger.info(f"ğŸ” Processing agent {i}: {agent}")
                    agent_id = agent["agent_id"]
                    agent_name = agent["name"]
                    agent_caps = agent["capabilities"]
                    logger.info(f"âœ… Agent {i} data extracted: id={agent_id}, name={agent_name}, caps={agent_caps}")
                except Exception as e:
                    logger.error(f"âŒ Error extracting agent {i} data: {e}")
                    logger.error(f"âŒ Agent object: {agent}")
                    raise
                
                # Create context-aware agent prompt for initial contribution
                agent_prompt = f"""You are {agent_name}, specializing in {', '.join(agent_caps)}.
You are collaborating with {num_agents-1} other agents to complete this task:

Task: {task_data.get('title', '')}
Description: {task_data.get('description', '')}

Other agents in this collaboration: {[a['name'] for a in agents_info if a['name'] != agent_name]}

As the expert in {', '.join(agent_caps)}, please provide your initial analysis and contribution to this task. Focus on:
1. How your expertise applies to this specific task
2. Your proposed approach or solution from your domain perspective
3. Key considerations or challenges you foresee
4. What you'll need from other agents to succeed

This is your initial contribution - be specific and actionable.
"""
                
                # Get agent response
                agent_conversation = conversation.copy()
                agent_conversation.append({
                    "role": "user", 
                    "content": agent_prompt
                })
                
                try:
                    logger.info(f"ğŸ”„ Calling OpenAI API for agent {agent_name}...")
                    response = await self._call_openai_api(agent_conversation)
                    logger.info(f"âœ… Agent {agent_name} provided initial contribution")
                except Exception as e:
                    logger.error(f"âŒ Agent {agent_name} failed to respond: {str(e)}")
                    logger.error(f"âŒ Error details: {type(e).__name__}: {e}")
                    import traceback
                    logger.error(f"âŒ Traceback: {traceback.format_exc()}")
                    response = f"[Agent {agent_name} encountered an error and could not contribute. This agent will be penalized.]"
                
                # Format and add response
                formatted_response = f"**{agent_name}** (Initial Contribution): {response}"
                conversation.append({
                    "role": "assistant", 
                    "content": formatted_response
                })
                
                # Update collaboration state
                collaboration_state["agent_responses"].append({
                    "agent": agent_name,
                    "agent_id": agent_id,
                    "phase": "initial",
                    "response": response,
                    "success": "error" not in response.lower()
                })
                
                await asyncio.sleep(0.3)  # Brief pause between agents
            
            # Phase 2: Collaborative refinement - ALL agents build on each other's work
            logger.info("ğŸ”„ Phase 2: Collaborative refinement from all agents")
            for i, agent in enumerate(agents_info):
                agent_id = agent["agent_id"]
                agent_name = agent["name"]
                agent_caps = agent["capabilities"]
                
                # Get other agents' contributions for context
                other_contributions = [resp for resp in collaboration_state["agent_responses"] 
                                     if resp["agent"] != agent_name and resp["success"]]
                
                collaboration_context = ""
                if other_contributions:
                    collaboration_context = "\nOther agents' contributions so far:\n"
                    for contrib in other_contributions[-3:]:  # Last 3 successful contributions
                        collaboration_context += f"- {contrib['agent']}: {contrib['response'][:150]}...\n"
                
                agent_prompt = f"""You are {agent_name}, continuing your collaboration.

{collaboration_context}

Now that you've seen other agents' contributions, please:
1. Build upon and integrate with other agents' ideas
2. Refine your approach based on their input
3. Address any gaps or challenges identified by the team
4. Propose next steps for the collaborative solution

Focus on creating synergy between all agents' expertise to deliver the best result.
"""
                
                # Get agent response
                agent_conversation = conversation.copy()
                agent_conversation.append({
                    "role": "user", 
                    "content": agent_prompt
                })
                
                try:
                    response = await self._call_openai_api(agent_conversation)
                    logger.info(f"âœ… Agent {agent_name} provided refinement")
                except Exception as e:
                    logger.error(f"âŒ Agent {agent_name} failed in refinement: {str(e)}")
                    response = f"[Agent {agent_name} encountered an error during refinement. This agent will be penalized.]"
                
                # Format and add response
                formatted_response = f"**{agent_name}** (Refinement): {response}"
                conversation.append({
                    "role": "assistant", 
                    "content": formatted_response
                })
                
                # Update collaboration state
                collaboration_state["agent_responses"].append({
                    "agent": agent_name,
                    "agent_id": agent_id,
                    "phase": "refinement",
                    "response": response,
                    "success": "error" not in response.lower()
                })
                
                await asyncio.sleep(0.3)  # Brief pause between agents
            
            # Final integration and summary
            integration_prompt = f"""Please provide a comprehensive summary of this multi-agent collaboration:

Task: {task_data.get('title', '')}
Description: {task_data.get('description', '')}

Please include:
1. Final integrated solution
2. Each agent's key contributions
3. How the collaboration enhanced the result
4. Task completion confirmation

Ensure the final result is complete, coherent, and actionable.
"""
            
            conversation.append({
                "role": "user", 
                "content": integration_prompt
            })
            
            final_response = await self._call_openai_api(conversation)
            conversation.append({
                "role": "assistant", 
                "content": f"Collaboration Summary: {final_response}"
            })
            
            return conversation, collaboration_state
            
        except Exception as e:
            logger.error(f"Error in enhanced conversation generation: {str(e)}")
            mock_conversation = self._generate_mock_conversation(task_data, agents_info, conversation)
            return mock_conversation, {"agent_responses": []}
    
    def _build_collaboration_context(self, collaboration_state: Dict, agents_info: List[Dict], round_num: int) -> str:
        """Build context for better agent collaboration"""
        context = ""
        
        if round_num > 0:
            context += "\nPrevious contributions from the team:\n"
            recent_responses = collaboration_state["agent_responses"][-3:]  # Last 3 responses
            for resp in recent_responses:
                context += f"- {resp['agent']}: {resp['response'][:100]}...\n"
        
        if round_num >= 3:
            context += f"\nWe are {round_num * 14}% through the task. Focus on building upon previous work and moving toward completion.\n"
        
        return context
    
    async def _call_openai_api(self, messages: List[Dict]) -> str:
        """
        è°ƒç”¨OpenAI APIï¼Œå¦‚æœå¤±è´¥åˆ™è‡ªåŠ¨åˆ‡æ¢åˆ°DeepSeek API
        """
        # é¦–å…ˆå°è¯•OpenAI API
        try:
            logger.info(f"ğŸ”¥ ATTEMPTING OPENAI API CALL! Model: {self.default_model}")
            if not self.openai_client:
                raise Exception("OpenAI client not initialized")
            
            response = await self.openai_client.chat.completions.create(
                model=self.default_model,
                messages=messages,
                max_tokens=1000,
                temperature=0.7
            )
            logger.info(f"âœ… OpenAI API call successful! Response length: {len(response.choices[0].message.content)}")
            return response.choices[0].message.content
            
        except Exception as openai_error:
            logger.warning(f"âš ï¸ OpenAI API failed: {str(openai_error)}")
            
            # å¦‚æœOpenAIå¤±è´¥ï¼Œå°è¯•DeepSeek APIä½œä¸ºå¤‡ç”¨
            try:
                logger.info("ğŸ”„ Falling back to DeepSeek API...")
                if not hasattr(self, 'deepseek_client') or not self.deepseek_client:
                    raise Exception("DeepSeek client not initialized")
                
                # ä½¿ç”¨DeepSeekæ¨¡å‹
                deepseek_model = os.environ.get('DEEPSEEK_MODEL', 'deepseek-chat')
                
                response = await self.deepseek_client.chat.completions.create(
                    model=deepseek_model,
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.7
                )
                logger.info(f"âœ… DeepSeek API call successful! Response length: {len(response.choices[0].message.content)}")
                return response.choices[0].message.content
                
            except Exception as deepseek_error:
                logger.error(f"âŒ Both OpenAI and DeepSeek APIs failed!")
                logger.error(f"âŒ OpenAI error: {openai_error}")
                logger.error(f"âŒ DeepSeek error: {deepseek_error}")
                
                # å¦‚æœä¸¤ä¸ªAPIéƒ½å¤±è´¥ï¼Œè¿”å›æ™ºèƒ½æ¨¡æ‹Ÿå“åº”
                logger.info("ğŸ¤– Using intelligent mock response as final fallback...")
                return self._generate_intelligent_mock_response(messages)
    
    def _generate_intelligent_mock_response(self, messages: List[Dict]) -> str:
        """
        ç”Ÿæˆæ™ºèƒ½æ¨¡æ‹Ÿå“åº”ï¼ˆå½“æ‰€æœ‰APIéƒ½å¤±è´¥æ—¶çš„æœ€åå¤‡ç”¨æ–¹æ¡ˆï¼‰
        """
        # æå–ä»»åŠ¡ä¿¡æ¯
        task_content = ""
        for msg in messages:
            if msg.get('role') == 'user':
                task_content = msg.get('content', '')
                break
        
        # åŸºäºä»»åŠ¡å†…å®¹ç”Ÿæˆç›¸å…³çš„æ¨¡æ‹Ÿå“åº”
        if 'classification' in task_content.lower() or 'åˆ†ç±»' in task_content:
            return """ä½œä¸ºAIä»£ç†ï¼Œæˆ‘å°†è¿›è¡Œå›¾åƒåˆ†ç±»åˆ†æï¼š

1. **æŠ€æœ¯æ–¹æ¡ˆ**: ä½¿ç”¨æ·±åº¦å­¦ä¹ CNNæ¨¡å‹è¿›è¡Œå›¾åƒç‰¹å¾æå–å’Œåˆ†ç±»
2. **å¤„ç†æµç¨‹**: 
   - å›¾åƒé¢„å¤„ç†ï¼ˆresize, normalizeï¼‰
   - ç‰¹å¾æå–ï¼ˆå·ç§¯å±‚ï¼‰
   - åˆ†ç±»é¢„æµ‹ï¼ˆå…¨è¿æ¥å±‚ï¼‰
3. **é¢„æœŸç»“æœ**: æä¾›åˆ†ç±»æ ‡ç­¾å’Œç½®ä¿¡åº¦è¯„åˆ†
4. **è´¨é‡ä¿è¯**: å¯¹ä½ç½®ä¿¡åº¦ç»“æœè¿›è¡Œäººå·¥éªŒè¯

è¿™ä¸ªä»»åŠ¡å·²ç»å®ŒæˆåŸºç¡€åˆ†ææ¡†æ¶è®¾è®¡ã€‚"""
        
        elif 'content generation' in task_content.lower() or 'å†…å®¹ç”Ÿæˆ' in task_content:
            return """ä½œä¸ºå†…å®¹ç”Ÿæˆä¸“å®¶ï¼Œæˆ‘æä¾›ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š

1. **å†…å®¹ç­–ç•¥**: åŸºäºç›®æ ‡å—ä¼—å’Œå¹³å°ç‰¹æ€§åˆ¶å®šå†…å®¹è®¡åˆ’
2. **ç”Ÿæˆæµç¨‹**: 
   - ä¸»é¢˜ç ”ç©¶å’Œå…³é”®è¯åˆ†æ
   - å†…å®¹ç»“æ„è®¾è®¡
   - å¤šåª’ä½“ç´ ææ•´åˆ
3. **è´¨é‡æ§åˆ¶**: SEOä¼˜åŒ–ã€å¯è¯»æ€§æ£€æŸ¥ã€å“ç‰Œä¸€è‡´æ€§
4. **å‘å¸ƒç®¡é“**: è‡ªåŠ¨åŒ–å†…å®¹åˆ†å‘å’Œæ•ˆæœç›‘æ§

å†…å®¹ç”Ÿæˆç®¡é“æ¡†æ¶å·²å»ºç«‹å®Œæˆã€‚"""
        
        else:
            return """ä½œä¸ºAIåä½œä»£ç†ï¼Œæˆ‘å·²åˆ†æäº†ä»»åŠ¡éœ€æ±‚ï¼š

1. **ä»»åŠ¡ç†è§£**: å·²å®Œæˆéœ€æ±‚åˆ†æå’Œç›®æ ‡å®šä¹‰
2. **è§£å†³æ–¹æ¡ˆ**: åˆ¶å®šäº†ç³»ç»Ÿæ€§çš„å¤„ç†æ–¹æ³•
3. **æ‰§è¡Œè®¡åˆ’**: åˆ†æ­¥éª¤å®æ–½ï¼Œç¡®ä¿è´¨é‡å’Œæ•ˆç‡
4. **é¢„æœŸæˆæœ**: å°†äº¤ä»˜ç¬¦åˆè¦æ±‚çš„æœ€ç»ˆç»“æœ

ä»»åŠ¡å¤„ç†æ¡†æ¶å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹æ‰§è¡Œã€‚"""
    
    async def _record_to_blockchain(self, collaboration_id: str, ipfs_cid: str, task_id: str) -> str:
        """
        å°†IPFS CIDè®°å½•åˆ°åŒºå—é“¾
        """
        try:
            # è·å–é»˜è®¤å‘é€è€…åœ°å€ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥ä»ç¯å¢ƒå˜é‡æˆ–ç”¨æˆ·è¾“å…¥è·å–ï¼‰
            sender_address = os.environ.get('AGENT_ADDRESS', '0x0000000000000000000000000000000000000000')
            
            # è°ƒç”¨åŒºå—é“¾è®°å½•å‡½æ•°
            result = record_collaboration_ipfs(collaboration_id, ipfs_cid, task_id, sender_address)
            
            if result["success"]:
                logger.info(f"Successfully recorded IPFS CID to blockchain: {result['transaction_hash']}")
                return result["transaction_hash"]
            else:
                logger.warning(f"Failed to record to blockchain: {result['error']}")
                # è¿”å›æ¨¡æ‹Ÿçš„äº¤æ˜“å“ˆå¸Œä½œä¸ºå¤‡ç”¨
                return "0x" + uuid.uuid4().hex[:64]
            
        except Exception as e:
            logger.error(f"Error recording to blockchain: {str(e)}")
            return "0x" + uuid.uuid4().hex[:64]
    
    async def _update_agents_after_collaboration(self, agents_info: List[Dict], conversation: List[Dict], task_data: Dict, collaboration_state: Dict) -> List[Dict]:
        """
        åä½œå®Œæˆåæ›´æ–°ä»£ç†ä¿¡æ¯ï¼ˆè°ƒç”¨åˆçº¦ä¸­çš„å­¦ä¹ ç®—æ³•ï¼‰
        å¢åŠ å¯¹å¤±è´¥/æ‰çº¿agentsçš„æƒ©ç½šæœºåˆ¶
        """
        agent_updates = []
        sender_address = os.environ.get('AGENT_ADDRESS', '0x0000000000000000000000000000000000000000')
        
        try:
            # ç»Ÿè®¡æ¯ä¸ªagentçš„å‚ä¸æƒ…å†µ
            agent_performance = {}
            
            for agent in agents_info:
                agent_id = agent['agent_id']
                agent_name = agent['name']
                
                # ä»collaboration_stateè·å–è¯¦ç»†çš„å‚ä¸ä¿¡æ¯
                agent_responses = [resp for resp in collaboration_state["agent_responses"] 
                                 if resp["agent_id"] == agent_id]
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                total_responses = len(agent_responses)
                successful_responses = len([resp for resp in agent_responses if resp["success"]])
                failed_responses = total_responses - successful_responses
                
                # è®¡ç®—å‚ä¸è´¨é‡åˆ†æ•°
                if total_responses > 0:
                    success_rate = successful_responses / total_responses
                    participation_score = success_rate * 100  # åŸºç¡€åˆ†æ•°ï¼šæˆåŠŸç‡
                    
                    # é¢å¤–å¥–åŠ±ï¼šå®Œæ•´å‚ä¸ä¸¤ä¸ªé˜¶æ®µ
                    phases_participated = len(set(resp["phase"] for resp in agent_responses if resp["success"]))
                    if phases_participated >= 2:  # å‚ä¸äº†initialå’Œrefinementé˜¶æ®µ
                        participation_score += 20  # å®Œæ•´å‚ä¸å¥–åŠ±
                    
                    # æƒ©ç½šï¼šå¤±è´¥å“åº”
                    participation_score -= failed_responses * 30  # æ¯æ¬¡å¤±è´¥æ‰£30åˆ†
                    
                    # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
                    participation_score = max(0, min(100, participation_score))
                else:
                    # å®Œå…¨æ²¡æœ‰å‚ä¸çš„agent
                    participation_score = 0
                    failed_responses = 2  # è§†ä¸ºä¸¤æ¬¡å¤±è´¥ï¼ˆåˆå§‹å’Œç²¾ç‚¼é˜¶æ®µï¼‰
                
                agent_performance[agent_id] = {
                    "agent_name": agent_name,
                    "participation_score": participation_score,
                    "total_responses": total_responses,
                    "successful_responses": successful_responses,
                    "failed_responses": failed_responses,
                    "success_rate": success_rate if total_responses > 0 else 0,
                    "status": "active" if successful_responses > 0 else "failed/offline"
                }
                
                logger.info(f"ğŸ” Agent {agent_name} performance: Score={participation_score:.1f}, Success={successful_responses}/{total_responses}, Status={agent_performance[agent_id]['status']}")
                
                # è°ƒç”¨åˆçº¦çš„å­¦ä¹ äº‹ä»¶è®°å½•åŠŸèƒ½æ¥æ›´æ–°ä»£ç†
                learning_data = {
                    "collaboration_id": task_data.get("task_id", ""),
                    "performance_score": participation_score,
                    "task_type": task_data.get("type", "general"),
                    "agent_contributions": successful_responses,
                    "failed_attempts": failed_responses,
                    "quality_metrics": {
                        "total_responses": total_responses,
                        "successful_responses": successful_responses,
                        "failed_responses": failed_responses,
                        "success_rate": success_rate if total_responses > 0 else 0,
                        "phases_participated": len(set(resp["phase"] for resp in agent_responses if resp["success"])),
                        "status": agent_performance[agent_id]["status"]
                    }
                }
                
                # æ¨¡æ‹Ÿè®°å½•å­¦ä¹ äº‹ä»¶ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨åˆçº¦ä¸­çš„å­¦ä¹ ç®—æ³•ï¼‰
                # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æˆåŠŸç»“æœ
                result = {
                    "success": True,
                    "transaction_hash": "0x" + uuid.uuid4().hex[:64],
                    "event_id": f"event_{uuid.uuid4().hex[:16]}",
                    "block_number": 12345 + len(agent_updates)
                }
                
                if result["success"]:
                    logger.info(f"Recorded learning event for agent {agent_id}: {result['transaction_hash']}")
                    
                    # æ„å»ºä»£ç†æ›´æ–°ä¿¡æ¯
                    agent_update = {
                        "agent_id": agent_id,
                        "performance_score": participation_score,
                        "learning_event_id": result.get("event_id"),
                        "transaction_hash": result["transaction_hash"],
                        "block_number": result.get("block_number"),
                        "update_type": "collaboration_completion",
                        "metrics": learning_data["quality_metrics"]
                    }
                    agent_updates.append(agent_update)
                else:
                    logger.warning(f"Failed to record learning event for agent {agent_id}: {result['error']}")
                    
        except Exception as e:
            logger.error(f"Error updating agents after collaboration: {str(e)}")
        
        return agent_updates

    async def create_learning_event(self, agent_id: str, learning_event_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸ºagentåˆ›å»ºå­¦ä¹ äº‹ä»¶å¹¶æ›´æ–°å…¶å­¦ä¹ æ•°æ®
        """
        try:
            logger.info(f"ğŸ“š Creating learning event for agent {agent_id}")
            
            # å‡†å¤‡å­¦ä¹ äº‹ä»¶æ•°æ®
            event_data = learning_event_data.get("data", {})
            event_type = learning_event_data.get("event_type", "task_evaluation")
            
            # åˆ›å»ºå®Œæ•´çš„å­¦ä¹ äº‹ä»¶è®°å½•
            learning_event = {
                "event_id": f"learn_{uuid.uuid4().hex[:16]}",
                "agent_id": agent_id,
                "event_type": event_type,
                "timestamp": time.time(),
                "data": event_data,
                "task_id": event_data.get("task_id"),  # æ·»åŠ task_idåˆ°é¡¶å±‚ï¼Œç”¨äºæ•°æ®åº“å­˜å‚¨
                "blockchain_recorded": False,
                "transaction_hash": None
            }
            
            # è®°å½•åˆ°æ•°æ®åº“
            try:
                from services.collaboration_db_service import collaboration_db_service
                db_result = collaboration_db_service.create_learning_event(learning_event)
                learning_event["db_id"] = db_result.get("id")
                logger.info(f"âœ… Learning event recorded in database")
            except Exception as e:
                logger.warning(f"Failed to record learning event in database: {e}")
            
            # å°è¯•è®°å½•åˆ°åŒºå—é“¾ï¼ˆå¦‚æœè¿æ¥å¯ç”¨ï¼‰
            try:
                from services import contract_service
                if contract_service.w3 and contract_service.w3.is_connected():
                    # å‡†å¤‡åŒºå—é“¾æ•°æ®
                    blockchain_data = {
                        "agent_id": agent_id,
                        "event_type": event_type,
                        "performance_data": json.dumps({
                            "success": event_data.get("success", True),
                            "rating": event_data.get("rating", 5),
                            "reputation_change": event_data.get("reputation_change", 0),
                            "task_id": event_data.get("task_id", ""),
                            "capabilities_used": event_data.get("capabilities_used", [])
                        }),
                        "timestamp": int(time.time())
                    }
                    
                    # è°ƒç”¨æ™ºèƒ½åˆçº¦è®°å½•å­¦ä¹ äº‹ä»¶
                    contract_result = contract_service.record_learning_event(blockchain_data)
                    if contract_result.get("success"):
                        learning_event["blockchain_recorded"] = True
                        learning_event["transaction_hash"] = contract_result.get("transaction_hash")
                        learning_event["block_number"] = contract_result.get("block_number")
                        logger.info(f"ğŸ”— Learning event recorded on blockchain: {contract_result.get('transaction_hash')}")
                    else:
                        logger.warning(f"Failed to record learning event on blockchain: {contract_result.get('error')}")
                else:
                    logger.info("ğŸ“ Blockchain not available, learning event stored locally only")
            except Exception as e:
                logger.warning(f"Error recording learning event on blockchain: {e}")
            
            # æ›´æ–°agentçš„ç»Ÿè®¡æ•°æ®
            await self._update_agent_statistics(agent_id, event_data)
            
            logger.info(f"ğŸ‰ Learning event created successfully for agent {agent_id}")
            
            return {
                "success": True,
                "event_id": learning_event["event_id"],
                "agent_id": agent_id,
                "event_type": event_type,
                "blockchain_recorded": learning_event["blockchain_recorded"],
                "transaction_hash": learning_event.get("transaction_hash"),
                "timestamp": learning_event["timestamp"]
            }
            
        except Exception as e:
            logger.error(f"âŒ Error creating learning event for agent {agent_id}: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "agent_id": agent_id
            }

    async def _update_agent_statistics(self, agent_id: str, event_data: Dict[str, Any]):
        """
        æ ¹æ®å­¦ä¹ äº‹ä»¶æ›´æ–°agentçš„ç»Ÿè®¡æ•°æ®
        """
        try:
            success = event_data.get("success", True)
            rating = event_data.get("rating", 5)
            reputation_change = event_data.get("reputation_change", 0)
            reward = event_data.get("reward", 0)
            capabilities_used = event_data.get("capabilities_used", [])
            
            # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„ç»Ÿè®¡æ›´æ–°é€»è¾‘
            # ä¾‹å¦‚ï¼šæ›´æ–°agentçš„reputationã€average_scoreã€success_rateç­‰
            
            update_data = {
                "agent_id": agent_id,
                "reputation_change": reputation_change,
                "total_reward": reward,
                "task_count": 1,
                "success_count": 1 if success else 0,
                "average_rating": rating,
                "capabilities_exercised": capabilities_used,
                "last_activity": time.time()
            }
            
            logger.info(f"ğŸ“Š Updated statistics for agent {agent_id}: reputation {reputation_change:+d}, reward {reward}")
            
            return update_data
            
        except Exception as e:
            logger.error(f"Error updating agent statistics: {e}")
            return {}
    

# åˆ›å»ºå•ä¾‹å®ä¾‹
agent_collaboration_service = AgentCollaborationService()